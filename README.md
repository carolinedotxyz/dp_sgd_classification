<div align="center">

![Status: WIP](https://img.shields.io/badge/status-wip-orange)
![Python](https://img.shields.io/badge/python-3.8+-blue.svg)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-ee4c2c.svg)
[![Medium Article](https://img.shields.io/badge/Medium-My%20Article-black?logo=medium)](https://medium.com/@carolinedotxyz/teaching-vision-models-to-forget-the-true-cost-of-privacy-in-deep-learning-9e4dc775f6e2)


# Educational SGD vs. DP-SGD Image Classifier
### CelebA â€” Eyeglasses Attribute Classification

**An end-to-end educational workflow for understanding differential privacy in deep learning**

[Overview](#-overview) â€¢ [Quick Start](#-quick-start) â€¢ [Features](#-features) â€¢ [Project Structure](#-project-structure) â€¢ [Documentation](#-documentation)

ğŸ“– *For a full conceptual walkthrough, see my accompanying Medium article:*  
[Teaching Vision Models to Forget â€” The True Cost of Privacy in Deep Learning](https://medium.com/@carolinedotxyz/teaching-vision-models-to-forget-the-true-cost-of-privacy-in-deep-learning-9e4dc775f6e2)


</div>

---

## ğŸ“– Overview

This repository provides a **complete, educational workflow** for training image classifiers with differential privacy. From raw [CelebA](https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html) images to balanced subset creation, preprocessing, baseline CNN training, and differentially private training with **DP-SGD** (via [Opacus](https://opacus.ai/)).

> **Design Philosophy**: Instead of diving straight into opaque training loops, we prioritize **clarity over complexity**. Each stage is observable, testable, and modifiable â€” designed as a teaching tool.

<div align="center">

![Training Dynamics: Baseline vs DP-SGD](gif/training_dynamics_comparison.gif)

*Training dynamics comparison: Baseline SGD vs. DP-SGD*

</div>

### ğŸ¯ Primary Entry Point

**The main entry point is** [`notebooks/celeba_eyeglasses_workflow.ipynb`](notebooks/celeba_eyeglasses_workflow.ipynb)

This notebook provides an **end-to-end educational workflow** where you:

- Analyze the CelebA dataset and create balanced subsets
- Preprocess images with transparent, observable steps
- Train both baseline and DP-SGD models with matched hyperparameters
- Visualize and compare privacy-accuracy trade-offs

> **Note**: All steps are designed for learning. Each stage is observable, testable, and modifiable. Training can also be done programmatically using the modules in `src/training/`, but the notebook is recommended for understanding the complete workflow.

---

## âœ¨ Features

- **Differential Privacy**: Full DP-SGD implementation using Opacus
- **Educational Focus**: Transparent, well-documented code designed for learning
- **Matched-Pair Methodology**: Identical hyperparameters for baseline and DP-SGD enable direct privacy cost quantification
- **Centralized Configuration**: YAML-based config system for easy experimentation
- **Comprehensive Visualization**: Training curves, privacy-utility tradeoffs, and comparisons
- **Tested & Reproducible**: Full test suite and tracked experiments under `runs/`
- **Automated Workflows**: Hyperparameter sweeps for both baseline and DP-SGD

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8+
- pip

### 1ï¸âƒ£ Installation

```bash
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
pip install -U pip
pip install -e .[dev]
```

### 2ï¸âƒ£ Download the Data

1. Download the CelebA dataset from [Kaggle](https://www.kaggle.com/datasets/jessicali9530/celeba-dataset)
2. Extract and place the archive under:
   ```
   data/celeba/archive/
   ```
3. The notebook will validate the expected files/structure automatically

### 3ï¸âƒ£ Configuration (Optional)

The notebook uses a centralized YAML configuration system. Edit `notebooks/config.yaml` to customize:

- Dataset paths and subset sizes
- Preprocessing parameters
- Training hyperparameters
- Privacy parameters (for DP-SGD)

ğŸ“– See [`notebooks/README_config.md`](notebooks/README_config.md) for detailed configuration documentation.

### 4ï¸âƒ£ Create Subset and Preprocess

Open and run: [`notebooks/celeba_eyeglasses_workflow.ipynb`](notebooks/celeba_eyeglasses_workflow.ipynb)

The notebook will:
- Build a balanced Eyeglasses subset (train/val/test)
- Preprocess images (crop/resize/normalize)
- Save dataset statistics needed by loaders

> These artifacts are required before running training. We keep this step in-notebook to make the process transparent and learnable.

### 5ï¸âƒ£ Train Models

After preprocessing, you can train models by:

- Continuing in `notebooks/celeba_eyeglasses_workflow.ipynb`
- The notebook includes training cells for both baseline and DP-SGD models
- Uses matched hyperparameters for fair privacy-accuracy comparison
- Includes visualization cells for analyzing results

---

## ğŸ—ï¸ Project Structure

<details>
<summary><b>Click to expand project structure</b></summary>

```
dp_sgd_classification/
â”œâ”€â”€ data/                    # Dataset storage (CelebA archive, subsets, processed images)
â”‚   â””â”€â”€ celeba/
â”‚       â”œâ”€â”€ archive/         # Raw CelebA dataset
â”‚       â”œâ”€â”€ subsets/         # Balanced subsets
â”‚       â””â”€â”€ processed/       # Preprocessed images
â”œâ”€â”€ notebooks/               # Main workflow notebook, configs, and utilities
â”‚   â”œâ”€â”€ celeba_eyeglasses_workflow.ipynb  # Primary entry point
â”‚   â”œâ”€â”€ config.yaml          # Centralized configuration
â”‚   â””â”€â”€ README_config.md     # Configuration guide
â”œâ”€â”€ scripts/                 # Standalone CLI scripts for data processing
â”‚   â”œâ”€â”€ celeba_analyze.py
â”‚   â”œâ”€â”€ celeba_build_subset.py
â”‚   â”œâ”€â”€ celeba_preprocess.py
â”‚   â””â”€â”€ celeba_centering.py
â”œâ”€â”€ src/                     # Core Python package
â”‚   â”œâ”€â”€ config/              # Configuration management
â”‚   â”œâ”€â”€ core/                # Core ML components (models, data loaders, utils)
â”‚   â”œâ”€â”€ datasets/            # Dataset-specific code (CelebA workflow, analysis)
â”‚   â”œâ”€â”€ notebooks/           # Notebook utilities (display, setup, helpers)
â”‚   â”œâ”€â”€ training/            # Training loops, sweeps, visualization
â”‚   â””â”€â”€ visualization/       # Plotting utilities
â”œâ”€â”€ tests/                   # Test suite
â””â”€â”€ runs/                    # Training run outputs (configs, checkpoints, metrics)
```

</details>

---

## ğŸ§ª Testing

<details>
<summary><b>Click to expand testing instructions</b></summary>

Run the full test suite:

```bash
pytest -q
```

Or run specific test files:

```bash
pytest tests/test_data.py
pytest tests/test_train_baseline.py
pytest tests/test_train_dp.py
```

</details>

---

## ğŸ“¦ What You'll Find

<details>
<summary><b>Click to expand detailed component descriptions</b></summary>

### Data Processing Scripts (`scripts/`)

| Script | Description |
|--------|-------------|
| `celeba_analyze.py` | Analyze CelebA attribute balance |
| `celeba_build_subset.py` | Create balanced subsets with stratification |
| `celeba_preprocess.py` | Preprocess images (crop/resize/normalize) |
| `celeba_centering.py` | Analyze face centering using landmarks |

### Core Functionality (`src/`)

- **Configuration** (`src/config/`): Centralized YAML-based config system with platform-specific workarounds (e.g., M1 Mac OpenMP fixes)
- **Subset Building** (`src/datasets/celeba/`): Balanced Eyeglasses vs No Eyeglasses, with options to reduce confounding
- **Preprocessing** (`src/datasets/celeba/`): Deterministic center-crop/resize, normalization, and saved dataset stats
- **Training** (`src/training/`): Clear baseline (non-DP) and DP-SGD loops using PyTorch + Opacus
- **Hyperparameter Sweeps** (`src/training/`): Automated grid searches for baseline and DP-SGD
- **Visualization** (`src/visualization/`): Training curves, privacy-utility tradeoffs, and comparisons
- **Notebook Utilities** (`src/notebooks/`): Helper functions for timestamps, config printing, validation

### Notebook Features (`notebooks/`)

- âœ… **Centralized configuration**: YAML-based config system (`config.yaml`) for easy experimentation
- âœ… **Helper utilities**: Reusable functions (`generate_timestamp`, `print_config`, validation helpers)
- âœ… **Cell dependencies**: Clear documentation of global state and dependencies in notebook header
- âœ… **Code quality**: Well-documented, maintainable code following best practices
- âœ… **Matched-pair methodology**: Identical hyperparameters for baseline and DP-SGD enable direct privacy cost quantification

### Additional Features

- ğŸ”„ **Reproducibility**: Configs, metrics, and artifacts tracked under `runs/`
- ğŸ“š **Documentation**: Comprehensive guides in `docs/` for data processing, training, and notebooks

</details>

---

## ğŸ”— Recommended Reading

<details>
<summary><b>Click to expand learning resources</b></summary>

If you're new to **Differential Privacy**, **DP-SGD**, or the **CelebA dataset**, the following resources provide helpful background:

### Differential Privacy Fundamentals

- **"The Algorithmic Foundations of Differential Privacy" (Dwork & Roth)** â€” canonical introduction  
  [ğŸ“„ PDF](https://www.cis.upenn.edu/~aaroth/Papers/privacybook.pdf)

### DP-SGD and Practical Implementations

- **Original DP-SGD Paper: "Deep Learning with Differential Privacy"**  
  [ğŸ“„ arXiv](https://arxiv.org/abs/1607.00133)

- **Opacus (PyTorch) â€” DP-SGD Documentation**  
  [ğŸŒ Website](https://opacus.ai/docs)

- **TensorFlow Privacy â€” DP-SGD Overview**  
  [ğŸ™ GitHub](https://github.com/tensorflow/privacy)

### CelebA Dataset Background

- **CelebA Dataset Paper ("Deep Learning Face Attributesâ€¦")**  
  [ğŸ“„ arXiv](https://arxiv.org/abs/1411.7766)

- **CelebA Dataset Homepage & Documentation**  
  [ğŸŒ Website](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html)

### General DP Resources (Optional)

- **Apple Differential Privacy Technical Overview**  
  [ğŸ“„ PDF](https://www.apple.com/privacy/docs/Differential_Privacy_Overview.pdf)

- **Google's RAPPOR (Local DP technique)**  
  [ğŸ“„ Research Paper](https://research.google/pubs/pub42852/)

</details>

---

## ğŸ› ï¸ Tech Stack

<details>
<summary><b>Click to expand technology stack</b></summary>

- **Python** 3.8+
- **PyTorch** - Deep learning framework
- **Opacus** - Differential privacy for PyTorch
- **NumPy, Pandas** - Data processing
- **Matplotlib, Seaborn** - Visualization
- **Pytest** - Testing framework

</details>

---

## ğŸ—ºï¸ Roadmap

<details>
<summary><b>Click to expand roadmap</b></summary>

- [ ] Additional privacy budget analysis tools
- [ ] Support for more CelebA attributes
- [ ] Extended visualization capabilities
- [ ] Performance optimizations

</details>

---

## ğŸ™ Acknowledgments

<details>
<summary><b>Click to expand acknowledgments</b></summary>

- **[CelebA Dataset](https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html)** - The Chinese University of Hong Kong
- **[Opacus](https://opacus.ai/)** - Facebook AI Research for differential privacy tools

</details>

---

<div align="center">

**Built with â¤ï¸ for educational purposes**

</div>
