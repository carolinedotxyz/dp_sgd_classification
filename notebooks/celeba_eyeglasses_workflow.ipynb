{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DP-SGD vs. Baseline Training on CelebA\n",
    "\n",
    "This notebook compares standard training with Differential Privacy SGD (DP-SGD) on the CelebA eyeglasses classification task. We use **matched hyperparameters** and the **AdamW optimizer** for both approaches to isolate the privacy-accuracy trade-off.\n",
    "\n",
    "> **üí° Tip:** This notebook uses collapsible sections (click the headers to expand/collapse) to keep setup and utility scripts organized. You can collapse sections you've already run to focus on the current workflow step.\n",
    "\n",
    "<details style=\"border: 1px solid currentColor; border-radius: 6px; padding: 12px; margin: 10px 0;\">\n",
    "<summary style=\"font-size: 1.1em; font-weight: bold; cursor: pointer; padding: 8px;\"><a id=\"why-privacy-matters\"></a>üîí Why Does Privacy in Machine Learning Matter?</summary>\n",
    "\n",
    "**The Problem:** Standard machine learning models can leak sensitive information about their training data, even after training is complete.\n",
    "\n",
    "**Real-World Risks:**\n",
    "\n",
    "1. **Membership Inference Attacks**: An attacker can determine whether a specific person's data was used to train the model. For example:\n",
    "   - A healthcare model trained on patient records could reveal if your medical data was in the training set\n",
    "   - A face recognition model could reveal if your photo was used for training\n",
    "   - üìö Learn more: [Shokri et al. (2017) - Membership Inference Attacks](https://arxiv.org/abs/1610.05820)\n",
    "\n",
    "2. **Model Inversion Attacks**: Attackers can reconstruct training examples from the model. For instance:\n",
    "   - A model trained on medical images might allow reconstruction of patient faces\n",
    "   - A language model might reproduce verbatim text from training data\n",
    "   - üìö Learn more: [Fredrikson et al. (2015) - Model Inversion Attacks](https://www.cs.cmu.edu/~mfredrik/papers/fjr2015ccs.pdf)\n",
    "\n",
    "3. **Attribute Inference**: Models can reveal sensitive attributes about individuals:\n",
    "   - A model trained on public photos might leak private attributes (e.g., location, relationships)\n",
    "   - Financial models might reveal income or spending patterns\n",
    "   - üìö Learn more: [Fredrikson et al. (2014) - Privacy in Pharmacogenetics](https://www.cs.cmu.edu/~mfredrik/papers/fjr2014icml.pdf)\n",
    "\n",
    "**Why This Matters for CelebA:**\n",
    "CelebA contains celebrity photos with attributes. Without privacy protection, a trained model could:\n",
    "- Reveal which celebrities were in the training set\n",
    "- Potentially reconstruct training images\n",
    "- Leak sensitive attributes about individuals\n",
    "\n",
    "**The Solution:** Differential Privacy provides mathematical guarantees that individual training examples cannot be identified or reconstructed from the model, even by sophisticated attackers. üìö Learn more: [Dwork & Roth (2014) - The Algorithmic Foundations of Differential Privacy](https://www.cis.upenn.edu/~aaroth/Papers/privacybook.pdf)\n",
    "\n",
    "</details>\n",
    "\n",
    "<details style=\"border: 1px solid currentColor; border-radius: 6px; padding: 12px; margin: 10px 0;\">\n",
    "<summary style=\"font-size: 1.1em; font-weight: bold; cursor: pointer; padding: 8px;\"><a id=\"what-is-differential-privacy\"></a>üìä What is Differential Privacy? (Intuitive Explanation)</summary>\n",
    "\n",
    "**The Core Idea:** Differential Privacy ensures that the output of an algorithm (like a trained model) is **nearly identical** whether or not any single individual's data was included in the training set.\n",
    "\n",
    "**The \"Neighbor\" Analogy:**\n",
    "Imagine two training datasets that differ by exactly one person's data (these are called \"neighboring datasets\"). A differentially private algorithm produces outputs that are so similar for both datasets that an attacker cannot tell which dataset was used‚Äîand therefore cannot identify any individual.\n",
    "\n",
    "**The Privacy Parameter (Œµ, epsilon):**\n",
    "- **Lower Œµ = Stronger Privacy**: Œµ=0.1 means very strong privacy (outputs are nearly identical)\n",
    "- **Higher Œµ = Weaker Privacy**: Œµ=10 means weaker privacy (more information can leak)\n",
    "- **Common Values**: \n",
    "  - Œµ < 1: Very strong privacy (used for sensitive data like medical records)\n",
    "  - Œµ = 1-10: Moderate privacy (common for many applications)\n",
    "  - Œµ > 10: Weak privacy (may not provide meaningful protection)\n",
    "\n",
    "**Key Property:** Differential Privacy is **compositional**‚Äîif you use a private algorithm multiple times, you can track the total privacy budget consumed (Œµ_total = Œµ‚ÇÅ + Œµ‚ÇÇ + ...).\n",
    "\n",
    "**Why It's Powerful:** Unlike ad-hoc privacy techniques, differential privacy provides **mathematical guarantees** that hold even against attackers with unlimited computational power and background knowledge. üìö Learn more: [Dwork (2006) - Differential Privacy](https://www.microsoft.com/en-us/research/publication/differential-privacy/) | [Dwork & Roth Textbook](https://www.cis.upenn.edu/~aaroth/Papers/privacybook.pdf) | [NIST Privacy Engineering Guide](https://www.nist.gov/publications/differential-privacy-sharing-practices)\n",
    "\n",
    "</details>\n",
    "\n",
    "<details style=\"border: 1px solid currentColor; border-radius: 6px; padding: 12px; margin: 10px 0;\">\n",
    "<summary style=\"font-size: 1.1em; font-weight: bold; cursor: pointer; padding: 8px;\"><a id=\"what-is-dp-sgd\"></a>üí≠ What is DP-SGD?</summary>\n",
    "\n",
    "**Differential Privacy SGD (DP-SGD)** is a privacy-preserving machine learning algorithm that provides formal privacy guarantees during training. It modifies standard SGD by:\n",
    "- **Clipping gradients** to bound their sensitivity\n",
    "- **Adding calibrated noise** to gradients before updating model parameters\n",
    "- **Tracking privacy budget** (epsilon, Œµ) consumed during training\n",
    "- üìö Learn more: [Abadi et al. (2016) - Deep Learning with Differential Privacy](https://arxiv.org/abs/1607.00133)\n",
    "\n",
    "**How It Works (Step-by-Step):**\n",
    "\n",
    "1. **Standard SGD**: Computes gradients from a batch of training examples\n",
    "2. **Gradient Clipping**: Limits the maximum influence of any single example by clipping gradients to a fixed norm (e.g., 1.0)\n",
    "3. **Noise Addition**: Adds carefully calibrated Gaussian noise to the clipped gradients\n",
    "4. **Parameter Update**: Updates model parameters using the noisy gradients\n",
    "5. **Privacy Accounting**: Tracks how much privacy budget (Œµ) has been consumed\n",
    "\n",
    "**The Intuition:**\n",
    "- **Clipping** ensures no single example can have too much influence\n",
    "- **Noise** makes it impossible to determine which examples contributed to the gradient\n",
    "- **Accounting** ensures you know exactly how much privacy you've used\n",
    "\n",
    "**What It Protects Against:**\n",
    "- ‚úÖ Membership inference attacks (can't tell if a specific example was in training)\n",
    "- ‚úÖ Model inversion attacks (can't reconstruct training examples)\n",
    "- ‚úÖ Attribute inference (can't infer sensitive attributes about individuals)\n",
    "\n",
    "**The Trade-off:**\n",
    "Privacy comes at the cost of some accuracy. The noise in gradients makes training less efficient, and the model may converge to a slightly lower accuracy. This notebook quantifies this trade-off through matched-pair comparisons.\n",
    "\n",
    "**Implementation Resources:**\n",
    "- üìö [Opacus - PyTorch Privacy Library](https://opacus.ai/) - Official library for DP-SGD in PyTorch\n",
    "- üìö [Opacus Documentation](https://opacus.ai/api/) - API reference and tutorials\n",
    "- üìö [TensorFlow Privacy](https://github.com/tensorflow/privacy) - DP-SGD implementation for TensorFlow\n",
    "- üìö [R√©nyi Differential Privacy](https://arxiv.org/abs/1702.07476) - Advanced privacy accounting used by Opacus\n",
    "\n",
    "</details>\n",
    "\n",
    "\n",
    "</details>\n",
    "\n",
    "<details style=\"border: 1px solid currentColor; border-radius: 6px; padding: 12px; margin: 10px 0;\">\n",
    "<summary style=\"font-size: 1.1em; font-weight: bold; cursor: pointer; padding: 8px;\"><a id=\"why-eyeglasses\"></a>üëì Why Eyeglasses?</summary>\n",
    "\n",
    "The eyeglasses attribute provides a balanced binary classification task with less cultural bias than alternatives (e.g., smile detection), making it suitable for evaluating privacy-preserving methods.\n",
    "\n",
    "</details>\n",
    "\n",
    "\n",
    "<details style=\"border: 1px solid currentColor; border-radius: 6px; padding: 12px; margin: 10px 0;\">\n",
    "<summary style=\"font-size: 1.1em; font-weight: bold; cursor: pointer; padding: 8px;\"><a id=\"workflow-overview\"></a>üîÄ Workflow Overview</summary>\n",
    "\n",
    "**Setup** ‚Üí **Data Pipeline** ‚Üí **Training** ‚Üí **Analysis**\n",
    "\n",
    "1. **Setup**: Environment configuration and paths\n",
    "2. **Data Pipeline**: Archive review ‚Üí balanced subset ‚Üí preprocessing ‚Üí validation\n",
    "3. **Training**: Baseline (non-private) and DP-SGD (privacy-preserving) with identical hyperparameters\n",
    "4. **Analysis**: Matched-pair comparison quantifying privacy cost\n",
    "\n",
    "</details>\n",
    "\n",
    "<details style=\"border: 1px solid currentColor; border-radius: 6px; padding: 12px; margin: 10px 0;\">\n",
    "<summary style=\"font-size: 1.1em; font-weight: bold; cursor: pointer; padding: 8px;\"><a id=\"prerequisites\"></a>‚úÖ Prerequisites</summary>\n",
    "\n",
    "- CelebA dataset at `data/celeba/archive/`\n",
    "- Run cells sequentially from top to bottom\n",
    "- Dependencies: `src/*` modules\n",
    "\n",
    "</details>\n",
    "\n",
    "<details style=\"border: 1px solid currentColor; border-radius: 6px; padding: 12px; margin: 10px 0;\">\n",
    "<summary style=\"font-size: 1.1em; font-weight: bold; cursor: pointer; padding: 8px;\"><a id=\"table-of-contents\"></a>üóÇÔ∏è Table of Contents</summary>\n",
    "\n",
    "## [0. Introduction](#introduction)\n",
    "- [0.1. Understanding DP-SGD: A Visual Demonstration](#dp-sgd-demo)\n",
    "\n",
    "## [1. Setup](#setup)\n",
    "\n",
    "## [2. Data Pipeline](#data-pipeline)\n",
    "- [2.1. Review the Archive](#review-the-archive)\n",
    "- [2.2. Build Subset](#build-subset)\n",
    "- [2.3. Analyze the Subset (Before Preprocessing)](#analyze-the-subset-before-preprocessing)\n",
    "- [2.4. Center-Crop Diagnostics (Optional)](#center-crop-diagnostics-optional)\n",
    "- [2.5. Preprocess Images](#preprocess-images)\n",
    "- [2.6. Validate Preprocessing](#validate-preprocessing)\n",
    "\n",
    "## [3. Training](#training)\n",
    "- [3.1 Baseline Training](#baseline-training)\n",
    "  - [3.1.1. Quick Run: Baseline Training](#quick-run-baseline-training)\n",
    "  - [3.1.2. Long Run: Baseline Training](#long-run-baseline-training)\n",
    "- [3.2 DP-SGD Training](#dp-sgd-training)\n",
    "  - [3.2.1. Quick Run: DP-SGD Training](#quick-run-dp-sgd-training)\n",
    "  - [3.2.2. Long Run: DP-SGD Training](#long-run-dp-sgd-training)\n",
    "\n",
    "## [4. Analysis](#analysis)\n",
    "- [4.1. Matched Pair Analysis](#matched-pair-analysis)\n",
    "- [4.2. Training Dynamics Comparison](#training-dynamics-comparison)\n",
    "- [4.3. Privacy-Accuracy Trade-off](#privacy-accuracy-trade-off)\n",
    "- [4.4. Summary](#summary)\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"introduction\"></a>Introduction\n",
    "\n",
    "### <a id=\"dp-sgd-demo\"></a> Understanding DP-SGD: A Visual Demonstration\n",
    "\n",
    "Okay, before we get started with the full workflow, let's understand the core mechanisms of DP-SGD through a hands-on demonstration. This will help you visualize how **gradient clipping** and **noise addition** work together to provide privacy guarantees.\n",
    "\n",
    "**What you'll see:**\n",
    "1. **Original gradients**: Simulated gradients from a batch (some may be large)\n",
    "2. **Clipped gradients**: Gradients after clipping to max norm (bounded influence)\n",
    "3. **Noisy gradients**: Clipped gradients with Gaussian noise added (privacy protection)\n",
    "4. **Comparison**: Visual comparison showing how clipping and noise affect gradients\n",
    "\n",
    "Run the code cell below to see these concepts in action!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Educational Demo: Gradient Clipping and Noise Addition in DP-SGD ---\n",
    "# This cell demonstrates the core mechanisms of DP-SGD without requiring full training setup.\n",
    "# It shows how gradients are clipped and noise is added to provide privacy guarantees.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Simulate gradients from a batch (some examples may have large gradients)\n",
    "# In real training, these would come from backpropagation\n",
    "batch_size = 10\n",
    "grad_dim = 5  # Simplified: just 5 gradient components\n",
    "original_gradients = np.random.randn(batch_size, grad_dim) * np.array([2, 1.5, 3, 0.5, 1.8])[None, :]\n",
    "\n",
    "# DP-SGD Step 1: Clip gradients to max norm (e.g., 1.0)\n",
    "max_grad_norm = 1.0\n",
    "gradient_norms = np.linalg.norm(original_gradients, axis=1, keepdims=True)\n",
    "clipping_factor = np.minimum(1.0, max_grad_norm / (gradient_norms + 1e-8))\n",
    "clipped_gradients = original_gradients * clipping_factor\n",
    "\n",
    "# DP-SGD Step 2: Add calibrated Gaussian noise\n",
    "noise_multiplier = 1.1\n",
    "# In DP-SGD, noise scale = noise_multiplier * max_grad_norm / batch_size\n",
    "noise_scale = noise_multiplier * max_grad_norm / batch_size\n",
    "noise = np.random.normal(0, noise_scale, clipped_gradients.shape)\n",
    "noisy_gradients = clipped_gradients + noise\n",
    "\n",
    "# Compute average gradients (what would be used for parameter updates)\n",
    "avg_original = np.mean(original_gradients, axis=0)\n",
    "avg_clipped = np.mean(clipped_gradients, axis=0)\n",
    "avg_noisy = np.mean(noisy_gradients, axis=0)\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Plot 1: Original gradients (before clipping)\n",
    "ax = axes[0, 0]\n",
    "im1 = ax.imshow(original_gradients, aspect='auto', cmap='RdBu_r', vmin=-3, vmax=3)\n",
    "ax.set_title('1. Original Gradients\\n(Some may be large)', fontsize=12, fontweight='bold')\n",
    "ax.set_xlabel('Gradient Component')\n",
    "ax.set_ylabel('Example in Batch')\n",
    "ax.set_yticks(range(batch_size))\n",
    "plt.colorbar(im1, ax=ax, label='Gradient Value')\n",
    "\n",
    "# Plot 2: Clipped gradients\n",
    "ax = axes[0, 1]\n",
    "im2 = ax.imshow(clipped_gradients, aspect='auto', cmap='RdBu_r', vmin=-3, vmax=3)\n",
    "ax.set_title('2. Clipped Gradients\\n(Bounded by max_norm=1.0)', fontsize=12, fontweight='bold')\n",
    "ax.set_xlabel('Gradient Component')\n",
    "ax.set_ylabel('Example in Batch')\n",
    "ax.set_yticks(range(batch_size))\n",
    "plt.colorbar(im2, ax=ax, label='Gradient Value')\n",
    "\n",
    "# Plot 3: Noisy gradients (final DP-SGD gradients)\n",
    "ax = axes[1, 0]\n",
    "im3 = ax.imshow(noisy_gradients, aspect='auto', cmap='RdBu_r', vmin=-3, vmax=3)\n",
    "ax.set_title('3. Noisy Gradients\\n(Clipped + Gaussian Noise)', fontsize=12, fontweight='bold')\n",
    "ax.set_xlabel('Gradient Component')\n",
    "ax.set_ylabel('Example in Batch')\n",
    "ax.set_yticks(range(batch_size))\n",
    "plt.colorbar(im3, ax=ax, label='Gradient Value')\n",
    "\n",
    "# Plot 4: Average gradients comparison\n",
    "ax = axes[1, 1]\n",
    "x = np.arange(grad_dim)\n",
    "width = 0.25\n",
    "ax.bar(x - width, avg_original, width, label='Original Avg', alpha=0.7)\n",
    "ax.bar(x, avg_clipped, width, label='Clipped Avg', alpha=0.7)\n",
    "ax.bar(x + width, avg_noisy, width, label='Noisy Avg (DP-SGD)', alpha=0.7)\n",
    "ax.set_title('4. Average Gradients Comparison\\n(Used for Parameter Updates)', fontsize=12, fontweight='bold')\n",
    "ax.set_xlabel('Gradient Component')\n",
    "ax.set_ylabel('Average Gradient Value')\n",
    "ax.set_xticks(x)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"üìä Summary Statistics:\")\n",
    "print(f\"   Original gradient norms: min={np.min(gradient_norms):.3f}, max={np.max(gradient_norms):.3f}, mean={np.mean(gradient_norms):.3f}\")\n",
    "print(f\"   Clipped gradient norms:   min={np.min(np.linalg.norm(clipped_gradients, axis=1)):.3f}, max={np.max(np.linalg.norm(clipped_gradients, axis=1)):.3f}, mean={np.mean(np.linalg.norm(clipped_gradients, axis=1)):.3f}\")\n",
    "print(f\"   Noise scale: {noise_scale:.4f} (noise_multiplier={noise_multiplier}, max_grad_norm={max_grad_norm}, batch_size={batch_size})\")\n",
    "print(f\"\\nüí° Key Insight:\")\n",
    "print(f\"   ‚Ä¢ Clipping bounds each example's influence (max norm = {max_grad_norm})\")\n",
    "print(f\"   ‚Ä¢ Noise makes it impossible to identify which examples contributed\")\n",
    "print(f\"   ‚Ä¢ The average noisy gradient is used for parameter updates (provides privacy)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Okay, let's get started! Now that we understand how **DP-SGD** works, let's set up the environment and begin the full workflow. The next cells will configure paths, imports, and prepare everything we need for training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"setup\"></a>1. Setup\n",
    "\n",
    "The setup cells below configure the environment and prepare everything needed for the workflow.\n",
    "\n",
    "**What's included:**\n",
    "- **Environment**: Path configuration, imports, logging, and YAML config loading\n",
    "- **Reproducibility**: Random seeding for Python, NumPy, and PyTorch\n",
    "- **Data paths**: Directory creation and workflow configuration initialization\n",
    "\n",
    "**Checks performed:**\n",
    "- ‚úÖ Repository structure and module imports\n",
    "- ‚úÖ Required dependencies (matplotlib, torch, etc.)\n",
    "- ‚úÖ Directory creation and path validation\n",
    "\n",
    "Run the setup cells below to initialize the environment. You'll see confirmation messages when setup completes successfully.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Environment Setup: Paths, Imports, Logging, and Seeding ---\n",
    "import sys\n",
    "import logging\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Path Setup: Must be done before importing from src ---\n",
    "def find_repo_root(start: Path) -> Path:\n",
    "    \"\"\"Find the repository root by looking for the 'src' directory.\"\"\"\n",
    "    for candidate in [start, *start.parents]:\n",
    "        if (candidate / \"src\").exists():\n",
    "            return candidate\n",
    "    raise RuntimeError(\"Could not locate repository root containing a 'src' directory.\")\n",
    "\n",
    "# Find and set up repository root\n",
    "PROJECT_ROOT = find_repo_root(Path.cwd())\n",
    "\n",
    "# Ensure repo root is on sys.path (front)\n",
    "root_str = str(PROJECT_ROOT)\n",
    "if root_str not in sys.path:\n",
    "    sys.path.insert(0, root_str)\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "except ImportError as e:\n",
    "    raise ImportError(\"matplotlib is required. Try: pip install matplotlib\") from e\n",
    "\n",
    "# Import centralized configuration (now that path is set up)\n",
    "from src.config import get_config\n",
    "\n",
    "# Get configuration\n",
    "config = get_config()\n",
    "\n",
    "# Logging setup: notebooks can re-run cells, so reset handlers\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(levelname)s: %(message)s\", force=True)\n",
    "logger = logging.getLogger(\"setup\")\n",
    "\n",
    "# Basic seeding from configuration\n",
    "RANDOM_SEED = config.random_seed\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Optional torch seeding (if available)\n",
    "try:\n",
    "    import torch\n",
    "    torch.manual_seed(RANDOM_SEED)\n",
    "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "except Exception:\n",
    "    # Torch isn't required for this cell; skip silently if absent\n",
    "    pass\n",
    "\n",
    "# --- Matplotlib Configuration ---\n",
    "# Configure matplotlib style from configuration\n",
    "try:\n",
    "    plt.style.use(config.matplotlib_style)\n",
    "    logger.info(f\"Using matplotlib style: {config.matplotlib_style}\")\n",
    "except Exception:\n",
    "    plt.style.use(config.matplotlib_style_fallback)\n",
    "    logger.info(f\"Using fallback matplotlib style: {config.matplotlib_style_fallback}\")\n",
    "\n",
    "# Set figure DPI from configuration\n",
    "plt.rcParams[\"figure.dpi\"] = config.figure_dpi\n",
    "\n",
    "# --- Path Verification and Summary ---\n",
    "repo_name = Path(PROJECT_ROOT).name\n",
    "logger.info(f\"Repository root: {repo_name}\")\n",
    "logger.info(f\"Python path includes: {repo_name}\")\n",
    "logger.info(f\"Matplotlib configured - DPI: {config.figure_dpi}\")\n",
    "logger.info(f\"Environment setup complete. Random seed: {RANDOM_SEED}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data Paths and Workflow Configuration ---\n",
    "# This cell sets up data paths, creates directories, imports workflow helpers, and creates the Config object.\n",
    "\n",
    "import importlib\n",
    "from src.notebooks.display import _relpath as _rp\n",
    "\n",
    "# Generate paths from centralized configuration\n",
    "paths = config.get_paths(PROJECT_ROOT)\n",
    "ARCHIVE_DIR = paths[\"archive_dir\"]\n",
    "IMAGES_ROOT = paths[\"images_root\"]\n",
    "OUTPUT_DIR = paths[\"output_dir\"]\n",
    "OUT_ROOT = paths[\"out_root\"]\n",
    "\n",
    "# Ensure directories exist\n",
    "for p in (OUTPUT_DIR, OUT_ROOT):\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Import workflow helpers\n",
    "try:\n",
    "    import src.datasets.celeba.workflow as _cw\n",
    "    _cw = importlib.reload(_cw)\n",
    "except Exception as e:\n",
    "    raise ImportError(\n",
    "        \"Failed to import or reload 'src.datasets.celeba.workflow'. \"\n",
    "        \"Check that 'src/' is under the repo root and module imports are valid.\"\n",
    "    ) from e\n",
    "\n",
    "from src.datasets.celeba.workflow import (\n",
    "    Config,\n",
    "    review_archive\n",
    ")\n",
    "\n",
    "# Create workflow config using centralized values and paths\n",
    "cfg = Config(\n",
    "    archive_dir=ARCHIVE_DIR,\n",
    "    images_root=IMAGES_ROOT,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    subset_root=OUTPUT_DIR,\n",
    "    out_root=OUT_ROOT,\n",
    "    attribute=config.attribute,\n",
    "    max_train=config.max_train_per_class,\n",
    "    max_val=config.max_val_per_class,\n",
    "    max_test=config.max_test_per_class,\n",
    "    link_mode=config.link_mode,\n",
    "    random_seed=config.random_seed,\n",
    ")\n",
    "\n",
    "logger.info(\"Configuration ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Preview key config values ---\n",
    "# Display workflow configuration for verification before proceeding\n",
    "\n",
    "from src.notebooks import print_config\n",
    "\n",
    "print(\"Paths:\")\n",
    "print(f\"  - archive_dir: {_rp(cfg.archive_dir)}\")\n",
    "print(f\"  - images_root: {_rp(cfg.images_root)}\")\n",
    "print(f\"  - subset_root: {_rp(cfg.subset_root)}\")\n",
    "print(f\"  - out_root: {_rp(cfg.out_root)}\")\n",
    "\n",
    "print(\"\\nSubset caps (per class):\")\n",
    "print_config(\"\", {\"train\": cfg.max_train, \"val\": cfg.max_val, \"test\": cfg.max_test}, indent=2)\n",
    "\n",
    "print(\"\\nPreprocess:\")\n",
    "print_config(\"\", {\n",
    "    \"size\": cfg.preprocess_size,\n",
    "    \"center_crop\": cfg.preprocess_center_crop,\n",
    "    \"normalize_01\": cfg.preprocess_normalize_01,\n",
    "    \"compute_stats\": cfg.preprocess_compute_stats\n",
    "}, indent=2)\n",
    "\n",
    "print(\"\\nFlags:\")\n",
    "print_config(\"\", {\"plot\": cfg.plot, \"dry_run\": cfg.dry_run, \"overwrite\": cfg.overwrite}, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"data-pipeline\"></a>2. Data Pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"review-the-archive\"></a>2.1. Review the Archive\n",
    "\n",
    "Examine the original CelebA dataset to assess attribute distributions and data integrity before subset creation.\n",
    "\n",
    "**Steps:**\n",
    "1. **Quick Visual Check (Optional)**: Sample 3 random images to verify accessibility\n",
    "2. **Full Archive Review**: Scan attribute distributions, validate data health, generate receipts\n",
    "\n",
    "**Key checks:**\n",
    "- Required CSV files present (`list_attr_celeba.csv`, `list_eval_partition.csv`)\n",
    "- Attribute balance: Eyeglasses is rare (~6-7% overall), requiring balanced sampling\n",
    "- Split consistency: Attribute distribution stable across train/val/test\n",
    "- Receipts: Summary files and plots for audit trail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Quick Visual Check (Optional): Sample images to verify dataset is accessible ---\n",
    "# This is a quick smoke test before the full archive review. You can skip this if confident the dataset is accessible.\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from src.notebooks.display import _relpath as _rp, find_and_sample_images\n",
    "\n",
    "# Configuration constants\n",
    "VISUAL_CHECK_SAMPLES = 3  # Number of images to sample for visual verification\n",
    "FIG_WIDTH_PER_IMAGE = 4  # Figure width multiplier per image\n",
    "FIG_HEIGHT = 4  # Figure height\n",
    "TITLE_FONTSIZE = 10  # Font size for image titles\n",
    "\n",
    "# Find and sample images using helper function\n",
    "sampled_images, total_count = find_and_sample_images(\n",
    "    cfg.images_root,\n",
    "    n_samples=VISUAL_CHECK_SAMPLES,\n",
    "    seed=config.random_seed\n",
    ")\n",
    "\n",
    "print(f\"Found {total_count} images in {_rp(cfg.images_root)}\")\n",
    "print(f\"Randomly sampled {len(sampled_images)} images for verification:\\n\")\n",
    "\n",
    "# Display the sampled images\n",
    "fig, axes = plt.subplots(1, len(sampled_images), figsize=(FIG_WIDTH_PER_IMAGE * len(sampled_images), FIG_HEIGHT))\n",
    "if len(sampled_images) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for idx, img_path in enumerate(sampled_images):\n",
    "    try:\n",
    "        # Load and display the image\n",
    "        img = Image.open(img_path)\n",
    "        axes[idx].imshow(img)\n",
    "        axes[idx].set_title(f\"Image {idx + 1}\\n{img_path.name}\", fontsize=TITLE_FONTSIZE)\n",
    "        axes[idx].axis('off')\n",
    "        print(f\"  ‚úì {img_path.name} ({img.size[0]}√ó{img.size[1]}) - {_rp(img_path)}\")\n",
    "    except Exception as e:\n",
    "        axes[idx].text(0.5, 0.5, f\"Error loading\\n{img_path.name}\\n{str(e)}\", \n",
    "                      ha='center', va='center', transform=axes[idx].transAxes)\n",
    "        axes[idx].axis('off')\n",
    "        print(f\"  ‚úó {img_path.name} - Error: {e}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n‚úÖ Dataset verification complete: {len(sampled_images)} images successfully loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Review archive: scan attribute distributions and check data health ---\n",
    "# This cell performs the full archive review (can be collapsed after first run)\n",
    "\n",
    "from src.notebooks.display import _relpath as _rp\n",
    "from src.notebooks import print_config\n",
    "\n",
    "print_config(\"Review archive\", {\n",
    "    \"archive_dir\": _rp(cfg.archive_dir),\n",
    "    \"plot_top_n_attrs\": config.plot_top_n_attrs\n",
    "})\n",
    "\n",
    "review_archive(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"build-subset\"></a>2.2. Build Subset\n",
    "\n",
    "Create a balanced eyeglasses subset with target class caps per split. Missing or inaccessible files are logged for accountability.\n",
    "\n",
    "**Output:**\n",
    "- Balanced 50/50 splits (eyeglasses vs no_eyeglasses) for train/val/test\n",
    "- Audit trail: `subset_index_eyeglasses.csv` with full record\n",
    "- Skipped files: `skipped_missing_images.csv` (verify if count is unexpectedly large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Build balanced eyeglasses subset ---\n",
    "# Creates a balanced 50/50 subset with target class caps per split.\n",
    "# Missing or inaccessible files are logged to skipped_missing_images.csv.\n",
    "\n",
    "from src.datasets.celeba.workflow import build_subset_with_skip_summary\n",
    "from src.notebooks import print_config\n",
    "\n",
    "subset_config = config.get_subset_config()\n",
    "print_config(\"Build subset\", {\n",
    "    \"attribute\": subset_config[\"attribute\"],\n",
    "    \"max_train\": subset_config[\"max_train_per_class\"],\n",
    "    \"max_val\": subset_config[\"max_val_per_class\"],\n",
    "    \"max_test\": subset_config[\"max_test_per_class\"],\n",
    "    \"link_mode\": subset_config[\"link_mode\"],\n",
    "    \"overwrite\": cfg.overwrite,\n",
    "    \"dry_run\": cfg.dry_run,\n",
    "    \"output_dir\": _rp(cfg.output_dir),\n",
    "})\n",
    "\n",
    "# Capture and summarize skipped images; write skipped_missing_images.csv\n",
    "build_subset_with_skip_summary(cfg, suppress_per_file_logs=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"analyze-the-subset-before-preprocessing\"></a>2.3. Analyze the Subset (Before Preprocessing)\n",
    "\n",
    "Now that the subset is built, we pause to measure it directly. This is the **working dataset** we'll actually train on. Catching size quirks or odd channel stats here is cheaper than discovering them mid-training.\n",
    "\n",
    "If the subset appears clean, balanced, and predictable, proceed with preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Analyze subset before preprocessing ---\n",
    "# Measures the working dataset directly: counts, geometry, format, and class balance.\n",
    "# This is the dataset we'll actually train on, so catching issues here is cheaper than mid-training.\n",
    "\n",
    "from src.datasets.celeba.workflow import analyze_original_subset\n",
    "\n",
    "analyze_original_subset(cfg, verbosity=\"brief\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"center-crop-diagnostics-optional\"></a>2.4. Center-Crop Diagnostics (Optional)\n",
    "\n",
    "Cropping is a design choice that affects what information the model sees. This diagnostic shows what the crop removes and whether the label of interest survives intact.\n",
    "\n",
    "**What to check:**\n",
    "- Averaged images pre/post crop should preserve the region of interest\n",
    "- Difference heatmaps show where pixels are lost (typically margins)\n",
    "- For eyeglasses, the crop should keep the face region centered\n",
    "\n",
    "If important content consistently falls outside the crop, consider padding instead of hard square cropping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Center-crop diagnostics (optional) ---\n",
    "# Shows what the crop removes and whether the label of interest survives intact.\n",
    "# Displays averaged images pre/post crop and difference heatmaps.\n",
    "\n",
    "from src.datasets.celeba.workflow import preview_center_crop_diagnostics\n",
    "from src.notebooks import print_config\n",
    "\n",
    "print_config(\"Diagnostics preview\", {\n",
    "    \"target_size\": config.diag_target_size,\n",
    "    \"sample\": config.diag_visual_sample\n",
    "})\n",
    "\n",
    "preview_center_crop_diagnostics(cfg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"preprocess-images\"></a>2.5. Preprocess Images\n",
    "\n",
    "Apply standard preprocessing transformations to create a uniform dataset:\n",
    "\n",
    "- **Center-crop ‚Üí resize (64√ó64)**: Uniform scale and aspect ratio\n",
    "- **Normalize to [0,1]**: Standard pixel scale for training\n",
    "- **Compute channel mean/std**: Calculated on train split for normalization\n",
    "- **Preserve split/class structure**: Maintains reproducibility and audit trail\n",
    "\n",
    "**Output**: Processed images with index CSV and summary files for audit trail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Preprocess images ---\n",
    "# Applies center-crop ‚Üí resize (64√ó64), normalizes to [0,1], and computes channel statistics.\n",
    "# Preserves split/class structure and generates index CSV and summary files for audit trail.\n",
    "\n",
    "from src.datasets.celeba.workflow import preprocess_images_only\n",
    "\n",
    "preprocess_images_only(cfg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"validate-preprocessing\"></a>2.6. Validate Preprocessing\n",
    "\n",
    "Quick validation of the processed dataset before training:\n",
    "\n",
    "**Checks performed:**\n",
    "- **Counts**: Total images and distribution across train/val/test splits with class balance\n",
    "- **Geometry**: Image dimensions and uniformity (all images should be the same size)\n",
    "- **Format**: Image file type and color channels (RGB)\n",
    "- **Data integrity**: Images are valid and loadable\n",
    "\n",
    "This provides a concise summary to confirm the dataset is ready for training. For detailed diagnostics, use the full analysis mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Analyze processed dataset ---\n",
    "# Quick validation: counts, geometry, format, and data integrity checks.\n",
    "# Confirms dataset is ready for training. Use full analysis mode for detailed diagnostics.\n",
    "\n",
    "from src.datasets.celeba.workflow import analyze_processed\n",
    "\n",
    "analyze_processed(cfg, verbosity=\"brief\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Verify preprocessing artifacts exist ---\n",
    "# Validates that required preprocessing output files (manifest, ledger) are present.\n",
    "# These files are needed for training and analysis.\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "MANIFEST_PATH = Path(cfg.out_root) / \"stats\" / \"manifest.csv\"\n",
    "LEDGER_PATH = Path(cfg.out_root) / \"stats\" / \"data_ledger.json\"\n",
    "\n",
    "if not MANIFEST_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Missing preprocessing manifest: {MANIFEST_PATH}\")\n",
    "if not LEDGER_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Missing preprocessing ledger: {LEDGER_PATH}\")\n",
    "\n",
    "print(\"‚úì Preprocessing receipts verified\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"training\"></a>3. Training\n",
    "\n",
    "This section covers model training using two approaches:\n",
    "\n",
    "1. **Baseline Training**: Standard (non-private) training using AdamW optimizer\n",
    "2. **DP-SGD Training**: Privacy-preserving training with differential privacy guarantees\n",
    "\n",
    "**Matched Pair Design:**\n",
    "Both approaches use **identical hyperparameters**, models, and data. This enables direct comparison to quantify the **privacy-accuracy trade-off**‚Äîhow much accuracy we sacrifice for privacy protection.\n",
    "\n",
    "**Training Options:**\n",
    "Each approach offers quick (5 epochs) and long (20 epochs) runs:\n",
    "- **Quick runs**: Fast demonstration of training dynamics\n",
    "- **Long runs**: Extended training for better convergence and more accurate analysis\n",
    "\n",
    "The analysis section will automatically use long run data when available for consistency.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"baseline-training\"></a>3.1 Baseline Training\n",
    "\n",
    "Train a non-private baseline using AdamW optimizer with a hyperparameter sweep. All configurations are identically replicated for DP-SGD training to isolate the privacy-accuracy trade-off.\n",
    "\n",
    "**Why AdamW?** Same optimizer for both approaches ensures fair comparison. AdamW properly decouples weight decay and works seamlessly with Opacus PrivacyEngine.\n",
    "\n",
    "**Configuration:**\n",
    "- 6 matched configurations (each has an identical DP-SGD counterpart)\n",
    "- Hyperparameters: Learning rates (0.0005-0.005), batch sizes (64, 128), weight decay (0.0, 0.0001)\n",
    "- Uses processed dataset and channel statistics from preprocessing\n",
    "\n",
    "**Training Options:**\n",
    "You can run either the quick run, the long run, or both:\n",
    "- **Quick (5 epochs)**: Fast demonstration of training dynamics\n",
    "- **Long (20 epochs)**: Extended training for full convergence\n",
    "\n",
    "**Note:** If you run both, the analysis cells will automatically use the long run data for consistency. The quick run is useful for quick exploration, while the long run provides better convergence patterns for analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Baseline Training: Setup (imports, device, paths, and loader helpers) ---\n",
    "# Apply platform-specific workarounds automatically\n",
    "# Getting the platform config automatically applies OpenMP workaround for M1 Macs\n",
    "\n",
    "from src.config import get_platform_config, log_platform_info\n",
    "\n",
    "# Initialize platform config (automatically applies workarounds)\n",
    "platform_config = get_platform_config()\n",
    "log_platform_info(logger)\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "from src.config import BaselineConfig\n",
    "from src.core import load_stats, build_dataloaders, SimpleCNN, get_device, set_seed, accuracy, evaluate\n",
    "\n",
    "# Device & seed from centralized configuration\n",
    "DEVICE = get_device()\n",
    "SEED = config.random_seed\n",
    "set_seed(SEED)\n",
    "\n",
    "# Processed dataset root and stats\n",
    "PROCESSED_ROOT = str(cfg.out_root)\n",
    "STATS_PATH = str(Path(cfg.out_root) / \"stats\" / \"stats.json\")\n",
    "\n",
    "# Sanity prints\n",
    "print({\"device\": str(DEVICE), \"seed\": SEED, \"processed_root\": _rp(PROCESSED_ROOT)})\n",
    "assert Path(STATS_PATH).exists(), f\"Missing stats file: {STATS_PATH}\"\n",
    "\n",
    "# Load channel stats once (used by all loaders)\n",
    "MEAN, STD = load_stats(STATS_PATH)\n",
    "\n",
    "# --- Loader helper (rebuilds for a given batch size) ---\n",
    "# Define a top-level worker_init_fn so it is picklable under 'spawn' (macOS)\n",
    "# The multiplier 9973 is a large prime number used to ensure different seeds for each worker\n",
    "WORKER_SEED_MULTIPLIER = 9973  # Large prime for worker seed differentiation\n",
    "\n",
    "def worker_init_fn(worker_id: int):\n",
    "    \"\"\"Initialize random seed for each dataloader worker to ensure reproducibility.\"\"\"\n",
    "    seed = (SEED + worker_id * WORKER_SEED_MULTIPLIER) % (2**32 - 1)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "\n",
    "def make_loaders(batch_size: int, num_workers: int = 0,  # Disable multiprocessing for reliability\n",
    "                 aug_flip: bool = True, aug_jitter: bool = False,\n",
    "                 aug_rotation: bool = False, rotation_degrees: float = 10.0):\n",
    "    \"\"\"Create train/val/test dataloaders with specified batch size and augmentation.\n",
    "    \n",
    "    Args:\n",
    "        batch_size: Number of samples per batch\n",
    "        num_workers: Number of worker processes (0 disables multiprocessing for reliability on macOS)\n",
    "        aug_flip: Whether to apply horizontal flip augmentation\n",
    "        aug_jitter: Whether to apply color jitter augmentation\n",
    "        aug_rotation: Whether to apply random rotation augmentation\n",
    "        rotation_degrees: Maximum rotation angle in degrees (only used if aug_rotation=True)\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (train_loader, val_loader, test_loader)\n",
    "    \"\"\"\n",
    "    # Use num_workers=0 to avoid multiprocessing issues on macOS\n",
    "    # This is slower but more reliable across platforms\n",
    "    \n",
    "    g = torch.Generator()\n",
    "    g.manual_seed(SEED)\n",
    "    return build_dataloaders(\n",
    "        data_root=PROCESSED_ROOT,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        mean=MEAN,\n",
    "        std=STD,\n",
    "        aug_flip=aug_flip,\n",
    "        aug_jitter=aug_jitter,\n",
    "        aug_rotation=aug_rotation,\n",
    "        rotation_degrees=rotation_degrees,\n",
    "        worker_init_fn=worker_init_fn,\n",
    "        generator=g,\n",
    "    )\n",
    "\n",
    "# Quick smoke test to verify loaders work correctly\n",
    "train_loader, val_loader, test_loader = make_loaders(batch_size=64)\n",
    "logger.info(f\"Loaders created successfully: train={len(train_loader)} batches, val={len(val_loader)} batches, test={len(test_loader)} batches\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Training Infrastructure: Import Helper Modules ---\n",
    "# All training functionality has been extracted to helper modules for better organization\n",
    "# and reusability across different experiments.\n",
    "\n",
    "from src.training import (\n",
    "    run_sgd_sweep_with_progress,\n",
    "    plot_training_curves\n",
    ")\n",
    "\n",
    "# Simple helper functions for this specific experiment\n",
    "def make_model():\n",
    "    \"\"\"Create a SimpleCNN model for eyeglasses classification.\n",
    "    \n",
    "    Returns:\n",
    "        SimpleCNN model moved to the configured device (CPU/GPU)\n",
    "    \"\"\"\n",
    "    return SimpleCNN(num_classes=2).to(DEVICE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plot Baseline Training Curves ---\n",
    "# Displays training curves for baseline training.\n",
    "# Prefers long run data if available (more epochs = better convergence), otherwise uses quick run data.\n",
    "# This ensures consistency with the analysis cells that also prefer long runs.\n",
    "\n",
    "# Check for both quick and long training histories using globals().get() to avoid linter warnings\n",
    "history_df_long = globals().get('history_df_long')\n",
    "history_df_quick = globals().get('history_df_quick')\n",
    "\n",
    "# Select baseline history (prefer long if available, consistent with analysis cells)\n",
    "if history_df_long is not None:\n",
    "    baseline_history = history_df_long\n",
    "    run_type = \"long\"\n",
    "elif history_df_quick is not None:\n",
    "    baseline_history = history_df_quick\n",
    "    run_type = \"quick\"\n",
    "else:\n",
    "    print(\"‚ùå No baseline training history found. Please run either:\")\n",
    "    print(\"   ‚Ä¢ Quick Run Baseline Training (Cell 22) ‚Üí creates 'history_df_quick'\")\n",
    "    print(\"   ‚Ä¢ Long Run Baseline Training (Cell 23) ‚Üí creates 'history_df_long'\")\n",
    "    raise NameError(\"Missing baseline training history. Run Cell 22 or Cell 23 first.\")\n",
    "\n",
    "# Plot training curves\n",
    "print(f\"‚úÖ Plotting baseline training curves ({run_type} run)...\")\n",
    "plot_training_curves(baseline_history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"quick-run-baseline-training\"></a>‚ö†Ô∏è 3.1.1 Quick Run: Baseline Training ‚ö†Ô∏è\n",
    "\n",
    "**This cell will run the quick baseline training (5 epochs).**\n",
    "\n",
    "This is a fast demonstration that trains for 5 epochs. If you want to see full convergence patterns, you can also run the long training cell below. If you run both, the analysis cells will automatically use the long run data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Quick Run: Baseline Training (5 epochs) ---\n",
    "# Fast demonstration with matched hyperparameter configurations.\n",
    "# All configurations use AdamW optimizer for fair comparison with DP-SGD.\n",
    "\n",
    "from src.notebooks import generate_timestamp, print_config\n",
    "\n",
    "training_config = config.get_training_config(quick=True)\n",
    "\n",
    "print(\"üìã Quick Run Configuration:\")\n",
    "print_config(\"\", {\n",
    "    \"Epochs\": training_config['epochs'],\n",
    "    \"Sweep ID\": training_config['sweep_id'],\n",
    "    \"Configurations\": f\"{len(training_config['sweep_grid'])} matched pairs\",\n",
    "    \"Optimizer\": \"AdamW (for fair comparison)\"\n",
    "}, indent=3)\n",
    "\n",
    "# Use the refactored sweep function with centralized configuration\n",
    "history_df_quick = run_sgd_sweep_with_progress(\n",
    "    grid=training_config[\"sweep_grid\"], \n",
    "    epochs=training_config[\"epochs\"], \n",
    "    sweep_id=training_config[\"sweep_id\"],\n",
    "    device=DEVICE,\n",
    "    make_model_fn=make_model,\n",
    "    make_loaders_fn=make_loaders,\n",
    "    num_workers=training_config[\"num_workers\"],\n",
    "    aug_flip=training_config[\"aug_flip\"],\n",
    "    aug_jitter=training_config[\"aug_jitter\"],\n",
    "    base_run_dir=training_config[\"base_run_dir\"]\n",
    ")\n",
    "\n",
    "# Plot training curves\n",
    "timestamp = generate_timestamp()\n",
    "filename_quick = f\"{timestamp}_baseline_quick_training_curves.png\"\n",
    "fig = plot_training_curves(history_df_quick, save_path=filename_quick)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"long-run-baseline-training\"></a>‚ö†Ô∏è 3.1.2 Long Run: Baseline Training ‚ö†Ô∏è\n",
    "\n",
    "**This cell will run the long baseline training (20 epochs).**\n",
    "\n",
    "This extended training provides better convergence patterns for analysis. You can run this instead of or in addition to the quick run above. If you run both, the analysis cells will automatically use this long run data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Optional Longer Run: Baseline Training (15 epochs) ---\n",
    "# Extended training to see full convergence patterns\n",
    "# This cell is intentionally left as a template for longer training runs.\n",
    "\n",
    "training_config_long = config.get_training_config(quick=False)\n",
    "\n",
    "print(\"üìã Longer Run Configuration:\")\n",
    "print(f\"   Epochs: {training_config_long['epochs']}\")\n",
    "print(f\"   Sweep ID: {training_config_long['sweep_id']}\")\n",
    "print(f\"   Configurations: {len(training_config_long['sweep_grid'])} matched pairs\")\n",
    "print(f\"   ‚ö†Ô∏è  This will take significantly longer than the quick run\")\n",
    "\n",
    "history_df_long = run_sgd_sweep_with_progress(\n",
    "    grid=training_config_long[\"sweep_grid\"], \n",
    "    epochs=training_config_long[\"epochs\"], \n",
    "    sweep_id=training_config_long[\"sweep_id\"],\n",
    "    device=DEVICE,\n",
    "    make_model_fn=make_model,\n",
    "    make_loaders_fn=make_loaders,\n",
    "    num_workers=training_config_long[\"num_workers\"],\n",
    "    aug_flip=training_config_long[\"aug_flip\"],\n",
    "    aug_jitter=training_config_long[\"aug_jitter\"],\n",
    "    base_run_dir=training_config_long[\"base_run_dir\"]\n",
    ")\n",
    "\n",
    "# Plot training curves for longer run\n",
    "from src.notebooks import generate_timestamp\n",
    "timestamp = generate_timestamp()\n",
    "filename_long = f\"{timestamp}_baseline_long_training_curves.png\"\n",
    "fig = plot_training_curves(history_df_long, save_path=filename_long)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"dp-sgd-training\"></a>3.2. DP-SGD Training\n",
    "\n",
    "Train with Differential Privacy SGD (DP-SGD) using AdamW optimizer with identical hyperparameter configurations as the baseline. The only difference is privacy-preserving mechanisms, enabling direct comparison of privacy-accuracy trade-offs.\n",
    "\n",
    "**Matched pair design:** Every baseline configuration has an identical DP-SGD counterpart with the same hyperparameters, optimizer, model, and data. Performance differences are due solely to privacy mechanisms.\n",
    "\n",
    "**Privacy configuration:**\n",
    "- Same 6 configurations as baseline\n",
    "- [Opacus PrivacyEngine](https://opacus.ai/api/privacy_engine/) with [RDP accounting](https://arxiv.org/abs/1702.07476)\n",
    "  - Noise multiplier: 1.1 (moderate privacy, good accuracy balance)\n",
    "  - Gradient clipping: max_grad_norm=1.0\n",
    "  - Privacy budget: Tracks epsilon (Œµ) throughout training\n",
    "\n",
    "**Understanding Epsilon (Œµ) Values You'll See:**\n",
    "\n",
    "During training, you'll see epsilon values reported. Here's what they mean in practice:\n",
    "\n",
    "- **Œµ < 1**: Very strong privacy (e.g., Œµ=0.5)\n",
    "  - Used for highly sensitive data (medical records, financial data)\n",
    "  - Strong protection against membership inference\n",
    "  - May require more epochs or larger datasets for good accuracy\n",
    "\n",
    "- **Œµ = 1-5**: Moderate privacy (e.g., Œµ=2.0)\n",
    "  - Common for many real-world applications\n",
    "  - Good balance between privacy and utility\n",
    "  - Provides meaningful protection while maintaining reasonable accuracy\n",
    "\n",
    "- **Œµ = 5-10**: Weaker privacy (e.g., Œµ=8.0)\n",
    "  - May still provide some protection\n",
    "  - Better accuracy, but privacy guarantees are weaker\n",
    "  - Often used when privacy is less critical\n",
    "\n",
    "- **Œµ > 10**: Very weak privacy\n",
    "  - Little to no meaningful protection\n",
    "  - Essentially equivalent to non-private training\n",
    "  - Not recommended for sensitive data\n",
    "\n",
    "**In this notebook:** With our configuration (noise_multiplier=1.1, 5-20 epochs), you'll typically see Œµ values in the range of 1-5, providing moderate privacy protection suitable for this educational demonstration. üìö Learn more about epsilon interpretation: [Dwork & Roth Textbook - Chapter 3](https://www.cis.upenn.edu/~aaroth/Papers/privacybook.pdf) | [NIST Guide on Choosing Epsilon](https://www.nist.gov/publications/differential-privacy-sharing-practices)\n",
    "\n",
    "**Training Options:**\n",
    "You can run either the quick run, the long run, or both:\n",
    "- **Quick (5 epochs)**: Fast demonstration of privacy-accuracy trade-offs\n",
    "- **Long (20 epochs)**: Extended training (DP-SGD often needs more epochs than baseline for convergence)\n",
    "\n",
    "**Note:** If you run both, the analysis cells will automatically use the long run data for consistency. The quick run is useful for quick exploration, while the long run provides better convergence patterns and more accurate privacy-accuracy trade-off analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"quick-run-dp-sgd-training\"></a>‚ö†Ô∏è 3.2.1. Quick Run: DP-SGD Training ‚ö†Ô∏è\n",
    "\n",
    "**This cell will run the quick DP-SGD training (5 epochs).**\n",
    "\n",
    "This is a fast demonstration that trains for 5 epochs with differential privacy. If you want to see full convergence patterns, you can also run the long training cell below. If you run both, the analysis cells will automatically use the long run data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- DP-SGD Training: Import Helper Modules ---\n",
    "# Reuses shared training infrastructure from Cell 19 (DEVICE, make_loaders, make_model)\n",
    "# This ensures both baseline and DP-SGD use identical setup for fair comparison\n",
    "\n",
    "from src.training import (\n",
    "    run_dp_sgd_sweep_with_progress,\n",
    "    plot_training_curves\n",
    ")\n",
    "\n",
    "# Reuse shared infrastructure:\n",
    "# - DEVICE, MEAN, STD from unified setup (Cell 19)\n",
    "# - make_loaders() function from unified setup (Cell 19)\n",
    "# - make_model() function from baseline section (Cell 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Quick Run: DP-SGD Training (5 epochs) ---\n",
    "# Fast demonstration with matched hyperparameter configurations (same as baseline).\n",
    "# Uses Opacus PrivacyEngine with RDP accounting for differential privacy guarantees.\n",
    "# Dependencies: config (from Cell 1), DEVICE (from Cell 19), make_model (from Cell 20), make_loaders (from Cell 19)\n",
    "\n",
    "from src.notebooks import generate_timestamp, print_config\n",
    "\n",
    "dp_sgd_config = config.get_dp_sgd_config(quick=True)\n",
    "\n",
    "print(\"üìã Quick Run Configuration:\")\n",
    "print_config(\"\", {\n",
    "    \"Epochs\": dp_sgd_config['epochs'],\n",
    "    \"Sweep ID\": dp_sgd_config['sweep_id'],\n",
    "    \"Configurations\": f\"{len(dp_sgd_config['sweep_grid'])} matched pairs (identical to baseline)\",\n",
    "    \"Privacy (noise_multiplier)\": dp_sgd_config['noise_multiplier'],\n",
    "    \"Privacy (max_grad_norm)\": dp_sgd_config['max_grad_norm'],\n",
    "    \"Optimizer\": \"AdamW (for fair comparison)\"\n",
    "}, indent=3)\n",
    "\n",
    "# Use the DP-SGD sweep function with centralized configuration\n",
    "dp_history_df_quick = run_dp_sgd_sweep_with_progress(\n",
    "    grid=dp_sgd_config[\"sweep_grid\"],\n",
    "    epochs=dp_sgd_config[\"epochs\"],\n",
    "    sweep_id=dp_sgd_config[\"sweep_id\"],\n",
    "    device=DEVICE,\n",
    "    make_model_fn=make_model,\n",
    "    make_loaders_fn=make_loaders,\n",
    "    num_workers=dp_sgd_config[\"num_workers\"],\n",
    "    aug_flip=dp_sgd_config[\"aug_flip\"],\n",
    "    aug_jitter=dp_sgd_config[\"aug_jitter\"],\n",
    "    base_run_dir=dp_sgd_config[\"base_run_dir\"],\n",
    "    max_grad_norm=dp_sgd_config[\"max_grad_norm\"],\n",
    "    noise_multiplier=dp_sgd_config[\"noise_multiplier\"],\n",
    "    target_delta=dp_sgd_config[\"target_delta\"]\n",
    ")\n",
    "\n",
    "# Plot training curves\n",
    "timestamp = generate_timestamp()\n",
    "filename_dp_quick = f\"{timestamp}_dp_sgd_quick_training_curves.png\"\n",
    "fig = plot_training_curves(dp_history_df_quick, save_path=filename_dp_quick)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"long-run-dp-sgd-training\"></a>‚ö†Ô∏è 3.2.2. Long Run: DP-SGD Training ‚ö†Ô∏è \n",
    "\n",
    "**This cell will run the long DP-SGD training (20 epochs).**\n",
    "\n",
    "This extended training provides better convergence patterns and more accurate privacy-accuracy trade-off analysis. You can run this instead of or in addition to the quick run above. If you run both, the analysis cells will automatically use this long run data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Optional Longer Run: DP-SGD Training (20 epochs) ---\n",
    "\n",
    "dp_sgd_config_long = config.get_dp_sgd_config(quick=False)\n",
    "\n",
    "print(\"üìã Longer Run Configuration:\")\n",
    "print(f\"   Epochs: {dp_sgd_config_long['epochs']}\")\n",
    "print(f\"   Sweep ID: {dp_sgd_config_long['sweep_id']}\")\n",
    "print(f\"   Configurations: {len(dp_sgd_config_long['sweep_grid'])} matched pairs (identical to baseline)\")\n",
    "print(f\"   Privacy: noise_multiplier={dp_sgd_config_long['noise_multiplier']}, max_grad_norm={dp_sgd_config_long['max_grad_norm']}\")\n",
    "print(f\"   ‚ö†Ô∏è  This will take significantly longer than the quick run\")\n",
    "\n",
    "dp_history_df_long = run_dp_sgd_sweep_with_progress(\n",
    "    grid=dp_sgd_config_long[\"sweep_grid\"],\n",
    "    epochs=dp_sgd_config_long[\"epochs\"],\n",
    "    sweep_id=dp_sgd_config_long[\"sweep_id\"],\n",
    "    device=DEVICE,\n",
    "    make_model_fn=make_model,\n",
    "    make_loaders_fn=make_loaders,\n",
    "    num_workers=dp_sgd_config_long[\"num_workers\"],\n",
    "    aug_flip=dp_sgd_config_long[\"aug_flip\"],\n",
    "    aug_jitter=dp_sgd_config_long[\"aug_jitter\"],\n",
    "    base_run_dir=dp_sgd_config_long[\"base_run_dir\"],\n",
    "    max_grad_norm=dp_sgd_config_long[\"max_grad_norm\"],\n",
    "    noise_multiplier=dp_sgd_config_long[\"noise_multiplier\"],\n",
    "    target_delta=dp_sgd_config_long[\"target_delta\"]\n",
    ")\n",
    "\n",
    "# Plot training curves for longer run\n",
    "from src.notebooks import generate_timestamp\n",
    "timestamp = generate_timestamp()\n",
    "filename_dp_long = f\"{timestamp}_dp_sgd_long_training_curves.png\"\n",
    "fig = plot_training_curves(dp_history_df_long, save_path=filename_dp_long)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"analysis\"></a>5. Analysis\n",
    "\n",
    "This section analyzes and compares the baseline and DP-SGD training results to quantify the **privacy-accuracy trade-off**.\n",
    "\n",
    "**What's coming up:**\n",
    "- **Matched Pair Analysis**: Direct comparison of baseline vs DP-SGD for identical configurations\n",
    "- **Training Dynamics**: Visual comparison of convergence patterns and training behavior\n",
    "- **Privacy-Accuracy Trade-off**: Visualization of how epsilon (privacy) relates to accuracy\n",
    "\n",
    "**Why this matters:**\n",
    "These analyses quantify the **privacy cost**‚Äîhow much accuracy we sacrifice for privacy protection. This helps you understand the practical implications of using DP-SGD and make informed decisions about privacy-utility trade-offs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"matched-pair-analysis\"></a>5.1. Matched Pair Analysis\n",
    "\n",
    "Compare baseline and DP-SGD training using **identical hyperparameters** to isolate the privacy-accuracy trade-off. Each baseline configuration has a corresponding DP-SGD configuration with the same learning rate, batch size, and weight decay.\n",
    "\n",
    "**What you'll see:**\n",
    "- Side-by-side training curves and accuracy comparisons\n",
    "- Privacy cost: accuracy differences between baseline and DP-SGD\n",
    "- Epsilon (Œµ) values: privacy budget consumed for each configuration\n",
    "\n",
    "**Key insight:** By controlling all variables except privacy mechanisms, we directly measure how much accuracy we sacrifice for privacy protection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Matched Pair Comparison\n",
    "#   Quick: history_df_quick (from Cell 21), dp_history_df_quick (from Cell 25)\n",
    "#   Long: history_df_long (from Cell 22), dp_history_df_long (from Cell 26)\n",
    "\n",
    "from src.training import (\n",
    "    plot_matched_pair_comparison,\n",
    "    plot_privacy_cost_summary\n",
    ")\n",
    "\n",
    "# Check for both quick and long training histories\n",
    "# Prefer long runs if available (more epochs = better convergence)\n",
    "# Works flexibly with any combination: both long, both quick, or mixed\n",
    "has_long_baseline = 'history_df_long' in globals()\n",
    "has_long_dp = 'dp_history_df_long' in globals()\n",
    "has_quick_baseline = 'history_df_quick' in globals()\n",
    "has_quick_dp = 'dp_history_df_quick' in globals()\n",
    "\n",
    "# Select baseline history (prefer long if available)\n",
    "if has_long_baseline:\n",
    "    baseline_history = history_df_long\n",
    "    baseline_type = \"long\"\n",
    "elif has_quick_baseline:\n",
    "    baseline_history = history_df_quick\n",
    "    baseline_type = \"quick\"\n",
    "else:\n",
    "    baseline_history = None\n",
    "    baseline_type = None\n",
    "\n",
    "# Select DP-SGD history (prefer long if available)\n",
    "if has_long_dp:\n",
    "    dp_history = dp_history_df_long\n",
    "    dp_type = \"long\"\n",
    "elif has_quick_dp:\n",
    "    dp_history = dp_history_df_quick\n",
    "    dp_type = \"quick\"\n",
    "else:\n",
    "    dp_history = None\n",
    "    dp_type = None\n",
    "\n",
    "# Validate that we have both histories\n",
    "if baseline_history is None or dp_history is None:\n",
    "    missing = []\n",
    "    if baseline_history is None:\n",
    "        missing.append(\"baseline training history\")\n",
    "    if dp_history is None:\n",
    "        missing.append(\"DP-SGD training history\")\n",
    "    \n",
    "    print(\"‚ùå Missing required training histories. Please run the following cells first:\")\n",
    "    print()\n",
    "    if baseline_history is None:\n",
    "        print(\"   ‚Ä¢ Quick Run Baseline Training (Cell 21) ‚Üí creates 'history_df_quick'\")\n",
    "        print(\"   ‚Ä¢ Long Run Baseline Training (Cell 22) ‚Üí creates 'history_df_long'\")\n",
    "    if dp_history is None:\n",
    "        print(\"   ‚Ä¢ Quick Run DP-SGD Training (Cell 25) ‚Üí creates 'dp_history_df_quick'\")\n",
    "        print(\"   ‚Ä¢ Long Run DP-SGD Training (Cell 26) ‚Üí creates 'dp_history_df_long'\")\n",
    "    print()\n",
    "    print(\"   After running those cells, return here to perform the matched pair analysis.\")\n",
    "    raise RuntimeError(f\"Missing required variables: {', '.join(missing)}\")\n",
    "\n",
    "# Success - display what we're using\n",
    "if baseline_type == dp_type:\n",
    "    run_type = baseline_type\n",
    "    print(f\"‚úÖ Found training histories. Using {run_type} run data for matched pair analysis...\")\n",
    "else:\n",
    "    print(f\"‚úÖ Found training histories. Using mixed run types: baseline={baseline_type}, DP-SGD={dp_type}\")\n",
    "print(f\"   ‚Ä¢ Baseline: {len(baseline_history)} records ({baseline_type})\")\n",
    "print(f\"   ‚Ä¢ DP-SGD: {len(dp_history)} records ({dp_type})\")\n",
    "if (has_long_baseline or has_long_dp) and (has_quick_baseline or has_quick_dp):\n",
    "    print(\"   ‚ÑπÔ∏è  Note: Both long and quick run data detected. Using long where available.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Privacy Cost Summary: Detailed Analysis with Epsilon Values ---\n",
    "# Creates a summary table and visualization showing privacy costs across all configurations.\n",
    "# Shows accuracy differences and epsilon (Œµ) privacy budget consumption.\n",
    "# Dependencies: baseline_history, dp_history (set by Cell 18 - supports both quick and long runs)\n",
    "\n",
    "from src.notebooks import generate_timestamp\n",
    "\n",
    "# Check that Cell 18 has set up the history variables\n",
    "if 'baseline_history' in globals() and 'dp_history' in globals():\n",
    "    timestamp = generate_timestamp()\n",
    "    filename_summary = f\"{timestamp}_privacy_cost_summary.png\"\n",
    "    \n",
    "    fig = plot_privacy_cost_summary(\n",
    "        baseline_history=baseline_history,\n",
    "        dp_history=dp_history,\n",
    "        save_path=filename_summary\n",
    "    )\n",
    "    print(f\"‚úÖ Privacy cost summary saved: {filename_summary}\")\n",
    "else:\n",
    "    print(\"‚ùå Missing training histories. Please run Cell 18 first.\")\n",
    "    print(\"   Cell 18 validates dependencies and sets baseline_history and dp_history.\")\n",
    "    print(\"   It supports both quick and long training runs.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"training-dynamics-comparison\"></a>5.2. Training Dynamics Comparison\n",
    "\n",
    "Visualize how DP-SGD affects training dynamics compared to baseline. This shows:\n",
    "- Slower convergence due to noise in gradients\n",
    "- Lower final accuracy (privacy cost)\n",
    "- Training behavior differences for matched configurations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Training Dynamics Comparison: Baseline vs DP-SGD ---\n",
    "# Visualizes how DP-SGD affects training dynamics compared to baseline.\n",
    "# Shows slower convergence and lower final accuracy (privacy cost) for matched configurations.\n",
    "# Dependencies: baseline_history, dp_history (set by Cell 18 - supports both quick and long runs)\n",
    "\n",
    "from src.training import plot_training_dynamics_comparison\n",
    "from src.notebooks import generate_timestamp\n",
    "\n",
    "# Configuration: number of top configurations to display\n",
    "MAX_CONFIGS_TO_DISPLAY = 3  # Show top configurations by baseline accuracy\n",
    "\n",
    "# Check that Cell 18 has set up the history variables\n",
    "if 'baseline_history' in globals() and 'dp_history' in globals():\n",
    "    timestamp = generate_timestamp()\n",
    "    filename_dynamics = f\"{timestamp}_training_dynamics_comparison.png\"\n",
    "    \n",
    "    fig = plot_training_dynamics_comparison(\n",
    "        baseline_history=baseline_history,\n",
    "        dp_history=dp_history,\n",
    "        save_path=filename_dynamics,\n",
    "        max_configs=MAX_CONFIGS_TO_DISPLAY\n",
    "    )\n",
    "    print(f\"‚úÖ Training dynamics comparison saved: {filename_dynamics}\")\n",
    "else:\n",
    "    print(\"‚ùå Missing training histories. Please run Cell 18 first.\")\n",
    "    print(\"   Cell 18 validates dependencies and sets baseline_history and dp_history.\")\n",
    "    print(\"   It supports both quick and long training runs.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"privacy-accuracy-trade-off\"></a>5.3. Privacy-Accuracy Trade-off\n",
    "\n",
    "Visualize the fundamental DP-SGD trade-off: stronger privacy (lower epsilon) typically comes at the cost of lower accuracy. Each point represents a matched configuration.\n",
    "\n",
    "**What to Look For:**\n",
    "- **Lower Œµ (left side)**: Stronger privacy, but typically lower accuracy\n",
    "- **Higher Œµ (right side)**: Weaker privacy, but typically higher accuracy\n",
    "- **Ideal configurations**: Points in the upper-left region (high accuracy with low epsilon)\n",
    "- **Trade-off curve**: The general trend showing how accuracy decreases as privacy increases\n",
    "\n",
    "**Interpreting the Results:**\n",
    "- If all points cluster in the Œµ=1-5 range with good accuracy, you've achieved a good privacy-utility balance\n",
    "- If accuracy drops significantly even with moderate Œµ, you may need to adjust privacy parameters or use more training data\n",
    "- Remember: Œµ < 1 provides very strong privacy but may require more data/epochs for good accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Privacy-Accuracy Trade-off Visualization ---\n",
    "# Visualizes the fundamental DP-SGD trade-off: stronger privacy (lower epsilon) typically\n",
    "# comes at the cost of lower accuracy. Each point represents a matched configuration.\n",
    "# Dependencies: baseline_history, dp_history (set by Cell 18 - supports both quick and long runs)\n",
    "\n",
    "from src.training import plot_privacy_accuracy_tradeoff\n",
    "from src.notebooks import generate_timestamp\n",
    "\n",
    "# Check that Cell 18 has set up the history variables\n",
    "if 'baseline_history' in globals() and 'dp_history' in globals():\n",
    "    timestamp = generate_timestamp()\n",
    "    filename_tradeoff = f\"{timestamp}_privacy_accuracy_tradeoff.png\"\n",
    "    \n",
    "    fig = plot_privacy_accuracy_tradeoff(\n",
    "        baseline_history=baseline_history,\n",
    "        dp_history=dp_history,\n",
    "        save_path=filename_tradeoff\n",
    "    )\n",
    "    print(f\"‚úÖ Privacy-accuracy trade-off plot saved: {filename_tradeoff}\")\n",
    "else:\n",
    "    print(\"‚ùå Missing training histories. Please run Cell 18 first.\")\n",
    "    print(\"   Cell 18 validates dependencies and sets baseline_history and dp_history.\")\n",
    "    print(\"   It supports both quick and long training runs.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Matched Pair Comparison: Side-by-Side Visualization ---\n",
    "# Creates a comprehensive comparison showing baseline vs DP-SGD for each matched configuration.\n",
    "# Enables direct quantification of privacy cost across all hyperparameter combinations.\n",
    "# Dependencies: baseline_history, dp_history (set by Cell 18 - supports both quick and long runs)\n",
    "\n",
    "from src.notebooks import generate_timestamp\n",
    "\n",
    "# Check that Cell 18 has set up the history variables\n",
    "if 'baseline_history' in globals() and 'dp_history' in globals():\n",
    "    timestamp = generate_timestamp()\n",
    "    filename_comparison = f\"{timestamp}_matched_pair_comparison.png\"\n",
    "    \n",
    "    fig = plot_matched_pair_comparison(\n",
    "        baseline_history=baseline_history,\n",
    "        dp_history=dp_history,\n",
    "        save_path=filename_comparison\n",
    "    )\n",
    "    print(f\"‚úÖ Comparison plot saved: {filename_comparison}\")\n",
    "else:\n",
    "    print(\"‚ùå Missing training histories. Please run Cell 18 first.\")\n",
    "    print(\"   Cell 18 validates dependencies and sets baseline_history and dp_history.\")\n",
    "    print(\"   It supports both quick and long training runs.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"summary\"></a>6. Summary\n",
    "\n",
    "This notebook compared baseline and DP-SGD training on the CelebA eyeglasses classification task using matched hyperparameters to isolate the privacy-accuracy trade-off.\n",
    "\n",
    "**Key findings:**\n",
    "- Privacy-accuracy trade-off: DP-SGD provides differential privacy guarantees at the cost of some accuracy\n",
    "- Hyperparameter sensitivity: Different configurations respond differently to privacy mechanisms\n",
    "- Matched pair methodology: Using identical hyperparameters enables direct quantification of privacy cost\n",
    "\n",
    "**Key metrics:**\n",
    "- Privacy cost: Accuracy difference between baseline and DP-SGD for each configuration\n",
    "- Epsilon (Œµ): Privacy budget consumed (lower values = stronger privacy guarantees)\n",
    "- Configuration performance: Some hyperparameter combinations achieve better privacy-accuracy balance\n",
    "\n",
    "**Extensions:**\n",
    "- Explore different privacy parameters (`noise_multiplier`, `max_grad_norm`)\n",
    "- Longer training runs (uncomment 15-epoch cells for full convergence)\n",
    "- Different attributes (explore how privacy costs vary with task difficulty)\n",
    "- Architecture exploration (test which models are more privacy-friendly)\n",
    "- Advanced techniques: [PATE (Papernot et al., 2017)](https://arxiv.org/abs/1611.01277), [Federated Learning (McMahan et al., 2017)](https://arxiv.org/abs/1602.05629), [Private Aggregation of Teacher Ensembles](https://github.com/tensorflow/privacy/tree/master/research/pate_2017)\n",
    "\n",
    "**Resources:**\n",
    "\n",
    "**Foundational Papers:**\n",
    "- Differential Privacy: [Dwork & Roth (2014) - Textbook](https://www.cis.upenn.edu/~aaroth/Papers/privacybook.pdf) | [Dwork (2006) - Original Paper](https://www.microsoft.com/en-us/research/publication/differential-privacy/)\n",
    "- DP-SGD: [Abadi et al. (2016) - Deep Learning with Differential Privacy](https://arxiv.org/abs/1607.00133)\n",
    "- Privacy Attacks: [Shokri et al. (2017) - Membership Inference](https://arxiv.org/abs/1610.05820) | [Fredrikson et al. (2015) - Model Inversion](https://www.cs.cmu.edu/~mfredrik/papers/fjr2015ccs.pdf)\n",
    "\n",
    "**Implementation Libraries:**\n",
    "- [Opacus - PyTorch Privacy Library](https://opacus.ai/) - Official library for DP-SGD in PyTorch\n",
    "- [Opacus Documentation & Tutorials](https://opacus.ai/api/) - API reference and getting started guides\n",
    "- [TensorFlow Privacy](https://github.com/tensorflow/privacy) - DP-SGD implementation for TensorFlow\n",
    "\n",
    "**Privacy Accounting:**\n",
    "- [R√©nyi Differential Privacy (Mironov, 2017)](https://arxiv.org/abs/1702.07476) - Advanced privacy accounting used by Opacus\n",
    "- [Moments Accountant (Abadi et al., 2016)](https://arxiv.org/abs/1607.00133) - Privacy accounting method in DP-SGD\n",
    "\n",
    "**Additional Learning:**\n",
    "- [NIST Privacy Engineering Guide](https://www.nist.gov/publications/differential-privacy-sharing-practices) - Practical guidance on differential privacy\n",
    "- [CelebA Dataset](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html) - Large-scale face attributes dataset\n",
    "\n",
    "**Note:** Privacy is a property of the training algorithm, not the trained model. Privacy guarantees apply to the training data, not to inference on new examples.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dp-sgd-py312-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
